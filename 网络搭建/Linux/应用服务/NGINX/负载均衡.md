# 负载均衡

在多个应用实例之间进行负载均衡是一种常用的技术，用于优化资源利用率、最大化吞吐量、降低延迟并确保配置具有容错能力。



## 服务器组

为了使用 **NGINX** 对一组服务器进行 HTTP 流量负载均衡，首先需要通过 **upstream** 指令定义服务器组。该指令必须放置在 **http** 上下文中。

服务器组中的服务器使用 **server** 指令进行配置（请注意，这与定义 NGINX 虚拟服务器的 **server** 块不同）。例如，以下配置定义了一个名为 **backend** 的服务器组，包含三个服务器配置（可能解析为多个实际服务器）：

```nginx
http {
    upstream backend {
        server backend1.example.com weight=5;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }
}
```



要将请求传递到服务器组，需要在 **proxy_pass** 指令中指定服务器组的名称（对于其他协议，可使用 **fastcgi_pass**、**memcached_pass**、**scgi_pass** 或 **uwsgi_pass** 指令）。以下示例展示了一个运行在 NGINX 上的虚拟服务器，将所有请求转发到前面定义的 **backend** 上游组：

```nginx
server {
    location / {
        proxy_pass http://backend;
    }
}
```



以下示例整合了上述配置，展示了如何将 HTTP 请求代理到 **backend** 服务器组。该组包含三个服务器：两个运行同一应用程序实例，另一个作为备用。由于未在 **upstream** 块中指定负载均衡算法，**NGINX** 默认使用 **轮询算法**（Round Robin）：

```nginx
http {
    upstream backend {
        server backend1.example.com;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }

    server {
        location / {
            proxy_pass http://backend;
        }
    }
}
```



## 负载均衡算法

NGINX 支持四种负载均衡方法。



**轮询（Round Robin）** – 请求根据服务器权重均匀分布到各服务器。这是默认方法，无需特别指定指令：

```nginx
upstream backend {
    # 未指定负载均衡方法，默认为轮询
    server backend1.example.com;
    server backend2.example.com;
}
```



**最少连接（Least Connections）** – 请求发送到当前活跃连接数最少的服务器，同时考虑服务器权重：

```nginx
upstream backend {
    least_conn;
    server backend1.example.com;
    server backend2.example.com;
}
```



**IP 哈希（IP Hash）** – 根据客户端 IP 地址确定请求发送的服务器。使用 IPv4 地址的前三个八位字节或整个 IPv6 地址计算哈希值。该方法确保来自同一地址的请求始终发送到同一服务器，除非该服务器不可用：

```nginx
upstream backend {
    ip_hash;
    server backend1.example.com;
    server backend2.example.com;
}
```



如果需要暂时将某服务器从负载均衡轮转中移除，可以使用 down 参数标记，以保留当前客户端 IP 地址的哈希分配。原本应由该服务器处理的请求将自动发送到组中的下一个服务器：

```nginx
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    server backend3.example.com down;
}
```



**通用哈希（Generic Hash）** – 根据用户定义的键（可以是文本字符串、变量或组合）确定请求发送的服务器。例如，键可以是源 IP 地址和端口的组合，或如下例中的 URI：

```nginx
upstream backend {
    hash $request_uri consistent;
    server backend1.example.com;
    server backend2.example.com;
}
```

**hash 指令**支持通过 `consistent` 参数启用 **ketama 一致性哈希**负载均衡算法。该模式下，请求会根据用户定义的哈希键值均匀分配到所有上游服务器。**关键优势**在于：当上游服务器组发生变更（如新增或移除节点）时，仅少量键需要重新映射，从而显著减少缓存失效问题，尤其适用于依赖缓存或维护状态的应用程序。



**注意**：与默认的轮询（round-robin）不同，使用 `hash`、`ip_hash` 或 `least_conn` 等负载均衡方法时，相关配置指令必须置于上游块（upstream block）的 `server` 指令列表之前。



## 权重

在 NGINX 的负载均衡机制中，**权重（weight）** 是决定请求分发比例的关键参数。默认采用轮询（round-robin）算法进行请求分配，各服务器的权重值通过 `weight` 参数设置，默认权重为 1。

```nginx
upstream backend {
    server backend1.example.com weight=5;
    server backend2.example.com;
    server 192.0.0.1 backup;
}
```

`backend1.example.com` 配置了权重 5，而 `backend2.example.com` 保持默认权重 1。这意味着每 6 个请求中，5 个会优先分发到 `backend1.example.com`，1 个分发到 `backend2.example.com`。



## 备用服务器

**只有当所有主服务器（非 backup 标记的服务器）都不可用时**，NGINX 才会将请求转发到标记为 `backup` 的备用服务器。如果至少有一个主服务器可用，备用服务器就不会被启用。



NGINX 允许在 `upstream` 块中配置多个备用服务器，虽然备用服务器可以设置权重，但通常不建议。备用服务器的权重 (`weight`) 仅在**所有主服务器不可用**时生效，此时 NGINX 会按照备用服务器的权重分配请求。例如：

```nginx
upstream backend {
    server backend1.example.com;
    server backup1.example.com backup weight=2;
    server backup2.example.com backup weight=1;
}
```

当主服务器全部不可用时，NGINX 会以 **2:1** 的比例将请求分发给 `backup1` 和 `backup2`。但在实际生产环境中，备用服务器通常仅用于故障转移，因此设置权重的意义不大。





## 与多个工作进程共享数据

在 NGINX 中，当上游块不包含 `zone` 指令时，每个工作进程会保留独立的服务器组配置副本，并维护各自的计数器集合。这包括每个服务器当前的连接数和请求传递失败次数。因此，**服务器组配置无法动态修改**。

然而，一旦上游块包含 `zone` 指令，服务器组的配置便会存储在一个**所有工作进程共享的内存区域**中。这种共享机制使得动态配置成为可能，因为所有工作进程都能访问同一份组配置副本，并使用相同的相关计数器。

`zone` 指令对于实现**主动健康检查和上游组的动态重新配置至关重要**。此外，其他上游组功能也能从该指令中获益。

例如，如果组配置未共享，每个工作进程会维护各自的失败尝试计数器（由 `max_fails` 参数设置）。在这种情况下，由于每个请求仅由一个工作进程处理，如果某个工作进程未能成功将请求传递到服务器，其他工作进程对此将一无所知。这可能导致部分工作进程认为某服务器不可用，而其他工作进程却仍在向其发送请求。要使服务器被明确标记为不可用，在 `fail_timeout` 参数指定的时间范围内，失败尝试次数必须达到 `max_fails` 乘以工作进程数的总和。相比之下，`zone` 指令能够**确保预期的行为**，即所有工作进程共享失败计数。

同样，在低负载情况下，未使用 `zone` 指令的**最少连接负载均衡方法可能无法按预期工作**。该方法旨在将请求传递给活跃连接数最少的服务器。如果组配置未共享，每个工作进程会使用自己的连接数计数器，这可能导致它们将请求发送到另一个工作进程刚刚发送过请求的同一服务器。不过，增加请求数量可以减少这种影响。在高负载下，请求在工作进程间均匀分布，此时最少连接方法将按预期工作。



## 设置区域大小

由于使用模式差异很大，无法推荐一个理想的内存区域大小。所需的内存量取决于**启用的功能**（如会话保持、健康检查或 DNS 重新解析）以及**上游服务器的标识方式**。

例如，当使用 `sticky_route` 会话保持方法并启用单一健康检查时，一个 256 KB 的区域大致可容纳以下数量的上游服务器信息：

- **128 个服务器**（每个定义为 IP 地址:端口对）
- **88 个服务器**（每个定义为域名:端口对，其中域名解析为单个 IP 地址）
- **12 个服务器**（每个定义为域名:端口对，其中域名解析为多个 IP 地址）



## 被动健康检查

在被动健康检查机制下，NGINX 会在**事务发生时持续监控连接状态**，并尝试恢复任何失败的连接。如果连接仍无法恢复，NGINX 会将该服务器**标记为不可用**，并暂时停止向其发送请求，直至其被重新标记为可用。



要为每个上游服务器定义被标记为不可用的具体条件，可以通过在 `upstream` 块的 `server` 指令中设置以下参数：

- `fail_timeout`：此参数用于设定在特定时间内发生若干次失败尝试后，服务器将被标记为不可用。同时，它也**定义了服务器被标记为不可用的持续时间**（默认值为 10 秒）。
- `max_fails`：此参数设定了在 `fail_timeout` 时间段内，服务器必须发生的**失败尝试次数**，达到此次数后，服务器才会被标记为不可用（默认值为 1 次）。



以下示例中，如果 NGINX 在 30 秒内向某服务器发送请求失败或未收到响应 3 次，该服务器将被标记为不可用，持续 30 秒： 

```nginx
upstream backend {
    server backend1.example.com;
    server backend2.example.com max_fails=3 fail_timeout=30s;
}
```

需要注意的是，如果上游组中**仅有一个服务器**，那么 `fail_timeout` 和 `max_fails` 参数将被忽略，该服务器将**永远不会被标记为不可用**。



## 内容缓冲

当启用缓存功能时，NGINX 会将**上游服务器**响应保存到磁盘缓存中，并使用这些缓存响应客户端请求，无需每次都将相同内容的请求代理到后端服务器。



#### 启用响应缓存

要启用缓存功能，首先需要在 **http {}** 上下文中添加 **proxy_cache_path** 指令。该指令包含两个必选参数：

1. **缓存路径**：指定缓存内容在本地文件系统中的存储位置（如 `/data/nginx/cache`）。
2. **keys_zone**：定义共享内存区域的**名称和大小**，用于存储缓存项的元数据（如 `mycache:10m`）。

```nginx
http {
    # ...
    proxy_cache_path /data/nginx/cache keys_zone=mycache:10m;
}
```



接下来，在需要缓存服务器响应的上下文（如 **server** 或 **location**）中，使用 **proxy_cache** 指令指定缓存区域名称（即 **keys_zone** 定义的名称，如 `mycache`）：

```nginx
http {
    # ...
    proxy_cache_path /data/nginx/cache keys_zone=mycache:10m;
    server {
        proxy_cache mycache;
        location / {
            proxy_pass http://localhost:8000;
        }
    }
}
```

- **keys_zone** 定义的内存大小仅影响元数据存储，**不限制缓存数据的总量**。
- 缓存的实际数据存储在文件系统中，可通过 **max_size** 参数限制总缓存大小（但缓存可能临时超出该限制）。



#### 涉及缓存的 NGINX 进程

缓存功能涉及以下两个额外的 NGINX 进程：

- **缓存管理器**：定期激活以检查缓存状态。如果缓存的总大小**超过了 `proxy_cache_path` 指令中 `max_size` 参数设定的限制**（例如，你配置了 `max_size=10g`，缓存超过 10GB），它会移除“最近最少访问 (Least Recently Used, LRU)”的数据。所以在一个检查周期内，如果大量新数据被缓存，缓存的总大小可能会暂时性地超出 `max_size`。
- **缓存加载器**：仅在 NGINX 启动后运行一次，将之前缓存的元数据加载到共享内存区域。一次性加载整个缓存可能会消耗大量资源，导致 NGINX 在启动后的前几分钟性能下降。为避免此问题，可通过以下参数配置缓存的迭代加载：
  - loader_threshold： 每次迭代（即一次加载批次）持续的最大时间，单位是毫秒。
  - loader_files：每次迭代加载的最大缓存项目数（即文件或键值对的数量）。
  - loader_sleeps：每次迭代完成后的延迟时间，单位是毫秒。

以下示例配置每次迭代持续 300 毫秒或加载 200 个项目：

```nginx
proxy_cache_path /data/nginx/cache keys_zone=mycache:10m loader_threshold=300 loader_files=200;
```



#### 缓存特定请求

默认情况下，NGINX 会缓存代理服务器首次响应的 HTTP **GET 和 HEAD 请求**。NGINX Plus 使用请求字符串作为其唯一标识符（即“键”）。当后续请求的键与已缓存的响应匹配时，NGINX Plus 会将该缓存响应直接发送给客户端。为了更精细地控制哪些响应应被缓存，您可以在 `http {}`、`server {}` 或 `location {}` 上下文中添加多种指令。



若要更改用于计算请求键的特性，请使用 `proxy_cache_key` 指令。例如：

```nginx
proxy_cache_key "$host$request_uri$cookie_user";
```



若要定义同一请求键必须出现的最小次数，以便 NGINX 缓存其响应，可使用 `proxy_cache_min_uses` 指令。

例如，设置该值为 5 表示只有当同一请求被发送至少 5 次后，其响应才会被缓存：

```nginx
proxy_cache_min_uses 5;
```



如果需要缓存除 GET 和 HEAD 之外的其他 HTTP 方法的响应，可以在 `proxy_cache_methods` 指令中明确列出这些方法，同时包含 GET 和 HEAD。例如，要缓存 POST 请求的响应：

```nginx
proxy_cache_methods GET HEAD POST;
```



#### 限制或禁用缓存

默认情况下，缓存的响应会**无限期保留**。它们仅在缓存超过最大配置大小时，才会按照“最近最少访问”的顺序被移除。为了更精细地控制缓存行为，我们可以在 `http {}`、`server {}` 或 `location {}` 上下文中添加指令，以**设置缓存响应的有效时长，甚至完全禁用缓存**。



若要限制特定状态码的缓存响应的有效时长，可以使用 `proxy_cache_valid` 指令。例如：

```
proxy_cache_valid 200 302 10m;
proxy_cache_valid 404      1m;
```

在此示例中，**状态码为 200 或 302 的响应有效期为 10 分钟**，而**状态码为 404 的响应有效期则为 1 分钟**。



如果希望为所有状态码的响应定义统一的有效期，可以将 `any` 作为第一个参数，例如：

```
proxy_cache_valid any 5m;
```



若要定义 NGINX **不向客户端发送缓存响应的条件**，可使用 `proxy_cache_bypass` 指令。该指令的每个参数定义了一个条件，通常由若干变量组成。**只要至少有一个参数非空且不等于“0”**，NGINX 就不会查找缓存中的响应，而是会立即将请求转发到后端服务器。示例如下：

```
proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment;
```



如果需要定义 NGINX **不缓存响应的条件**，可以使用 `proxy_no_cache` 指令。其参数定义方式与 `proxy_cache_bypass` 相同，例如：

```
proxy_no_cache $http_pragma $http_authorization;
```



#### slice

在处理大文件时，**初始缓存填充操作常耗时较长**。以视频文件为例，当请求其一部分内容时，首次请求通常会触发整个文件的下载，而后续请求则需等待文件完全下载并存入缓存后才能响应。

为解决这一问题，NGINX **支持通过缓存分片模块（Cache Slice Module）实现字节范围缓存**，并逐步填充缓存。该模块的工作原理是将文件划分为若干“分片”。当接收到范围请求时，系统会选择覆盖该请求范围的特定分片。如果该分片尚未缓存，则将其存入缓存；此后，其他对这些分片的请求便可直接从缓存中获取数据。



使用 `slice` 指令指定分片大小：

```nginx
location / {
    slice  1m;
}
```



在缓存键中包含 `$slice_range` 变量：

```nginx
proxy_cache_key $uri$is_args$args$slice_range;
```



启用对 206 状态码响应的缓存：

```nginx
proxy_cache_valid 200 206 1h;
```



通过在 Range 头字段中设置 `$slice_range` 变量，启用将范围请求传递给代理服务器：

```nginx
proxy_set_header  Range $slice_range;
```



完整配置：

```nginx
location / {
    slice             1m;
    proxy_cache       cache;
    proxy_cache_key   $uri$is_args$args$slice_range;
    proxy_set_header  Range $slice_range;
    proxy_cache_valid 200 206 1h;
    proxy_pass        http://localhost:8000;
}
```

